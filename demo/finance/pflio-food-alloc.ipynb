{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6b4fa7-92a8-4a82-9182-f1a3f4b667a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys; sys.path.append(\"../../../foggy-statslib\")\n",
    "import foggy_statslib.core as fsc\n",
    "import foggy_statslib.fin as fsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f76ed31-3d44-4e42-a574-c6373ec17e5f",
   "metadata": {},
   "source": [
    "# MEAN-VARIANCE-OPTIMAL ALLOCATION\n",
    "\n",
    "Using the ideas from [my portfolio food pyramid](https://github.com/sparshsah/foggy-demo/blob/main/demo/finance/pflio-food.pdf)\n",
    "and [1-800-STYLS-4-U](https://github.com/sparshsah/foggy-demo/blob/main/demo/finance/styles4u.ipynb),\n",
    "we can construct a \"model portfolio\".\n",
    "I will run up the big categories from bottom to top of the pyramid,\n",
    "suggesting a sample vehicle for accessing it and ballparking its ex-ante Sharpe.\n",
    "\n",
    "Let us agree on the following conventions:\n",
    "* All PM stats (Sharpe, ER, Vol) are\n",
    "    * Long-term\n",
    "    * Annualized\n",
    "    * Excess-of-cash\n",
    "* If I leave it unqualified, the stat is gross-of-fee, but net-of-tcost-and-financing. So, it doesn't reflect what your manager is going to charge you for it, but it does reflect prime-brokerage commissions, shorting expenses, etc.\n",
    "* If I say \"net\", the stat is net of both fees and tcost-and-financing. So, it reflects management and performance fees paid to the manager in addition to the fees described above.\n",
    "* Here is an important nuance: When you look at the \"expense ratio\" of a mutual fund, you are looking at a mix of management fees and tcost-and-financing. Sometimes you'll even see a \"gross expense ratio\" and a lower \"net expense ratio\", with the latter reflecting a voluntary reimbursement by the manager. For example, if you see a gross expense ratio of 102bps and a net expense ratio of 99bps, then the manager is currently volunteering to reimburse you at an annualized 3bps (perhaps in this case because they desire some marketing benefit associated keeping an expense ratio less than 100bps). But this number does not compare cleanly from fund to fund, and it varies over time even when the manager has made no change to their policy. So, when you want to translate a gross-of-fee net-of-tcost-and-financing Sharpe to a net-net Sharpe, penalize by the _adjusted_ expense ratio. For a more in-depth explanation, see Morningstar's excellent article [\"One Expense Ratio to Rule Them All\"](https://www.morningstar.com/funds/one-expense-ratio-rule-them-all)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b289ea97-b524-46ec-8e19-7f31e61c2140",
   "metadata": {},
   "source": [
    "## Sample vehicles\n",
    "\n",
    "* Beta: We could use the [AQR Multi-Asset Risk-Parity Mutual Fund (AQRNX)](https://funds.aqr.com/funds/multi-asset/aqr-multi-asset-fund/aqrnx), which targets 10% vol, charging 1.06% adjusted expense ratio.\n",
    "    * Runner-up: [Bridgewater All-Weather Fund](https://www.bridgewater.com/research-and-insights/the-all-weather-story). Pros: Matches AQR's version in terms of diversification across asset classes and geographies, and All-Weather's track record is actually a smidge _longer_. I also just like the story a bit better. Cons: Not marketed to retail investors. Sad!\n",
    "* Macro: We could use the [AQR Managed Futures Mutual Fund (AQMNX)](https://funds.aqr.com/funds/alternatives/aqr-managed-futures-strategy-fund/aqmnx), which targets 10% vol, charging 1.51% adjusted expense ratio. The core strategy here is trend-following, plus some other stuff they're coy about in the prospectus but which I can confirm is good.\n",
    "* [Styles](https://github.com/sparshsah/foggy-demo/blob/main/demo/finance/styles4u.ipynb): We could use the [Vanguard Market-Neutral Equity Mutual Fund (VMNFX)](https://investor.vanguard.com/investment-products/mutual-funds/profile/vmnfx), which targets (I infer) 6% vol, charging 0.20% adjusted expense ratio.\n",
    "    * Runner-up: QSPNX (which is diversified across asset classes and geographies) or QMNNX (which not only adds more alpha-like signals, but also remains diversified across geographies despite---like VMNFX---being just stocks). Cons: They're both much more expensive in the face of a dirt-cheap 20bps. And really, the deciding factor is that we have too much AQR risk in our model portfolio already.\n",
    "* Special Situations: We could use the [AQR Diversified Arbitrage Mutual Fund (ADANX)](https://funds.aqr.com/funds/alternatives/aqr-diversified-arbitrage-fund/adanx), which targets a bit less than 5% vol but budgets for a bit heavier-than-usual tails (so let's call it effectively 6% vol), charging 1.50% adjusted expense ratio.\n",
    "    * Runner-up: [Driehaus Event-Driven Fund (DEVDX)](https://www.driehaus.com/funds/driehaus-event-driven-fund). Pros: Targets slightly higher vol, and is slightly cheaper. Cons: They don't do convertible arbitrage, and on top of that they're just not well-hedged (0.70-correlated to SPX, vs ADANX's 0.45)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03fdbe-4411-42cd-bbbc-e27dffdc6c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# my stylized ex-ante Sharpes\n",
    "sharpes = pd.Series({\n",
    "    \"beta\": 0.80,\n",
    "    # start with a base of 0.40, and add +0.10 reward for alphas i like e.g. AQR's GSS Factor Momentum\n",
    "    \"macro\": 0.50,\n",
    "    # start with a base of 0.40, and subtract -0.10 penalty for underdiversification (VMNFX is just stocks and just US)\n",
    "    \"styles\": 0.30,\n",
    "    \"spec_sits\": 0.40,\n",
    "})\n",
    "vols = pd.Series({\n",
    "    \"beta\": 0.10,\n",
    "    \"macro\": 0.10,\n",
    "    \"styles\": 0.06,\n",
    "    \"spec_sits\": 0.06,\n",
    "})\n",
    "fees = pd.Series({\n",
    "    \"beta\": 0.0106,\n",
    "    \"macro\": 0.0151,\n",
    "    \"styles\": 0.0020,\n",
    "    \"spec_sits\": 0.0150,\n",
    "})\n",
    "\n",
    "# assume uncorrelated\n",
    "corr = pd.DataFrame(\n",
    "    np.identity(len(sharpes)),\n",
    "    index=sharpes.index,\n",
    "    columns=sharpes.index,\n",
    ")\n",
    "\n",
    "# calculate\n",
    "sharpes_net = (sharpes*vols - fees) / vols\n",
    "ers_net = sharpes_net*vols\n",
    "stats = pd.DataFrame({\n",
    "    \"sharpe_net\": sharpes_net.apply(lambda v: f\"{v:.2f}\"),\n",
    "    \"er_net\": ers_net.apply(lambda v: f\"{v:.1%}\"),\n",
    "    \"vol\": vols.apply(lambda v: f\"{v:.0%}\"),\n",
    "})\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28812b16-f0db-4e02-9d4f-7b702f65a35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# notional allocation (i.e. $'s, not risk) in a unit-levered portfolio\n",
    "w = pd.DataFrame(\n",
    "    {\n",
    "        \"simple_mvo\": fsf._simple_mvo(\n",
    "            sharpe_vector=sharpes_net,\n",
    "            vol_vector=vols,\n",
    "            corr_matrix=corr,\n",
    "        )[0],\n",
    "        \"thumb_on_scaled\": pd.Series(\n",
    "            {\n",
    "                \"beta\": 0.40,\n",
    "                \"macro\": 0.25,\n",
    "                \"styles\": 0.20,\n",
    "                \"spec_sits\": 0.15,\n",
    "            }\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a84a0-633c-4986-9261-5e11954a13ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    env: fsf._get_exante_pm_stats_of_w_as_ser(\n",
    "        w,\n",
    "        er_vector=ers_net,\n",
    "        cov_matrix=fsc.compose_cov_matrix(vol_vector=vols, corr_matrix=corr),\n",
    "        fmt=True,\n",
    "    )\n",
    "    for (env, w) in w.items()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d61454-416f-41cd-9723-4d70b848d47e",
   "metadata": {},
   "source": [
    "# CONSERVATIVE VS AGGRESSIVE RISK-TAKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc650ab3-2e47-475c-8d6f-807fc70f9d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass(frozen=True)\n",
    "class History:\n",
    "    \"\"\"\n",
    "    Fields:\n",
    "        r: pd.DataFrame, The geometric returns.\n",
    "            Index = sims, Columns = years.\n",
    "        px: pd.DataFrame, The price index.\n",
    "        dd: pd.DataFrame, Current geometric drawdown level.\n",
    "    \"\"\"\n",
    "    r: pd.DataFrame = dataclasses.field(default_factory=pd.DataFrame)\n",
    "    px: pd.DataFrame = dataclasses.field(default_factory=pd.DataFrame)\n",
    "    dd: pd.DataFrame = dataclasses.field(default_factory=pd.DataFrame)\n",
    "    \n",
    "    def __init__(self, r: np.ndarray) -> None:\n",
    "        r = pd.DataFrame(\n",
    "            r,\n",
    "            index=pd.Index(range(r.shape[0]), name=\"sim\"),\n",
    "            columns=pd.Index(range(r.shape[1]), name=\"year\"),\n",
    "        )\n",
    "        r.loc[:, 0] = 0\n",
    "        r = r.clip(lower=-1)\n",
    "        # override frozen dataclass by reaching into internals\n",
    "        object.__setattr__(self, \"r\", r)\n",
    "        del r\n",
    "        px = (1 + self.r).cumprod(axis=\"columns\")\n",
    "        object.__setattr__(self, \"px\", px)\n",
    "        del px\n",
    "        dd = self.px / self.px.expanding().max() - 1\n",
    "        object.__setattr__(self, \"dd\", dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e74d6-2798-4616-8278-41f932bab080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sim_history(\n",
    "    er: float = 0.10,\n",
    "    vol: float = 0.10,\n",
    "    nyears: int = 50,\n",
    "    nsims: int = 1_000,\n",
    ") -> History:\n",
    "    r = np.random.default_rng(seed=42).normal(\n",
    "        loc=er, scale=vol, size=(nsims, nyears),\n",
    "    )\n",
    "    history = History(r=r)\n",
    "    return history\n",
    "\n",
    "# \"SPX\" -- really 15-17% vol, but left tails bring it to like 20% vol\n",
    "history_aggressive = sim_history(er=0.10, vol=0.20)\n",
    "# \"diversified\"\n",
    "history_conservative = sim_history(er=0.05, vol=0.05)\n",
    "avg_px = pd.DataFrame(\n",
    "    {\n",
    "        \"aggressive\": history_aggressive.px.median(),\n",
    "        \"conservative\": history_conservative.px.median(),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e48c2e-cd09-4035-9473-15bd30ae61ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(nrows=2)\n",
    "# terminals\n",
    "fsc.plot(\n",
    "    history_aggressive.px.iloc[:, -1],\n",
    "    kind=\"density\",\n",
    "    color=\"red\",\n",
    "    axvline_locs=[avg_px[\"aggressive\"].iloc[-1]],\n",
    "    axvline_styles=[\":\"],\n",
    "    axvline_colors=[\"red\"],\n",
    "    # plt\n",
    "    ax=ax[0],\n",
    ")\n",
    "fsc.plot(\n",
    "    history_conservative.px.iloc[:, -1],\n",
    "    kind=\"density\",\n",
    "    color=\"navy\",\n",
    "    axvline_locs=[avg_px[\"conservative\"].iloc[-1],],\n",
    "    axvline_styles=[\":\"],\n",
    "    axvline_colors=[\"navy\"],\n",
    "    # plt\n",
    "    title=\"DISTRIBUTION OF FINAL WEALTH:\",\n",
    "    ylim_bottom=0,\n",
    "    logx=True,\n",
    "    xlim_left=0.001,\n",
    "    xticklabels_fmt=lambda x, _: f\"${x:.2f}\" if x < 0.99 else f\"${x:.0f}\",\n",
    "    xlabel=\"\",\n",
    "    ax=ax[0],\n",
    ")\n",
    "# paths\n",
    "fsc.plot(\n",
    "    history_aggressive.px,\n",
    "    color=\"red\",\n",
    "    alpha=0.10,\n",
    "    # plt\n",
    "    ax=ax[1],\n",
    ")\n",
    "fsc.plot(\n",
    "    history_conservative.px,\n",
    "    color=\"navy\",\n",
    "    alpha=0.10,\n",
    "    ax=ax[1],\n",
    ")\n",
    "fsc.plot(\n",
    "    avg_px,\n",
    "    color=[\"red\", \"navy\"],\n",
    "    # plt\n",
    "    title=\"PATH OF WEALTH BY YEAR:\",\n",
    "    yticklabels_fmt=lambda y, _: f\"${y:.0f}\",\n",
    "    ylim_bottom=0.10,\n",
    "    logy=True,\n",
    "    xlabel=\"\",\n",
    "    legend=False,\n",
    "    figsize=(10, 8),\n",
    "    ax=ax[1],\n",
    ")\n",
    "# show\n",
    "print()\n",
    "plt.show()\n",
    "\n",
    "# stats\n",
    "qq = [0, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 1]\n",
    "print(\"\\nQuantiles of final wealth:\")\n",
    "print(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"aggressive\": history_aggressive.px.iloc[:, -1].quantile(qq),\n",
    "            \"conservative\": history_conservative.px.iloc[:, -1].quantile(qq),\n",
    "        },\n",
    "        index=pd.Index(qq, name=\"quantile\"),\n",
    "    )\n",
    "    .applymap(lambda x: f\"${x:,.2f}\" if x < 10 else f\"${x:,.0f}\")\n",
    "    .rename(index=lambda pctl: f\"{pctl * 100:,.0f}th\").T\n",
    ")\n",
    "print(\"\\nQuantiles of worst drawdown:\")\n",
    "print(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"aggressive\": history_aggressive.dd.min(axis=\"columns\").quantile(qq),\n",
    "            \"conservative\": history_conservative.dd.min(axis=\"columns\").quantile(qq),\n",
    "        },\n",
    "        index=pd.Index(qq, name=\"quantile\"),\n",
    "    )\n",
    "    .applymap(lambda x: f\"{x:.0%}\")\n",
    "    .rename(index=lambda pctl: f\"{pctl * 100:,.0f}th\").T\n",
    ")\n",
    "print(\"\\nQuantiles of worst annual return:\")\n",
    "print(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"aggressive\": history_aggressive.r.min(axis=\"columns\").quantile(qq),\n",
    "            \"conservative\": history_conservative.r.min(axis=\"columns\").quantile(qq),\n",
    "        },\n",
    "        index=pd.Index(qq, name=\"quantile\"),\n",
    "    )\n",
    "    .applymap(lambda x: f\"{x:.0%}\")\n",
    "    .rename(index=lambda pctl: f\"{pctl * 100:,.0f}th\").T\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
