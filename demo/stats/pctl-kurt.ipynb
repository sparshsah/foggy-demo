{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Quick-and-Dirty Attempt to Maximize \"Percentile Kurtosis\"\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Suppose someone tells you the event $X=x$ is a \"$+4\\sigma$ event\" i.e. that\n",
    "its $z$-score $z(X=x) = +4$. That sounds statistically extreme!\n",
    "$X=x$ seems like a very rare event. In other words, its percentile\n",
    "$\\Pr[X \\leq x]$ is probably very high.\n",
    "Indeed, if $X$ is Normal, $X=x$ would be essentially impossible.\n",
    "\n",
    "\n",
    "I want to try to construct a \"pathological\" example: A distribution\n",
    "with finite mean $\\mu$ and standard deviation $\\sigma$\n",
    "where an event as extreme as $X = x := \\mu + 4\\sigma$ (i.e. a $+4\\sigma$ event)\n",
    "is actually _very_ likely. This is hard, but I'll settle for\n",
    "making it _pretty_ likely.\n",
    "\n",
    "\n",
    "In other words, I want to construct a distribution that is highly \"percentile-kurtotic\":\n",
    "A distribution where $1 - \\Pr[X \\leq \\mu + 4\\sigma]$ is maximal.\n",
    "\n",
    "\n",
    "## Definitions\n",
    "\n",
    "### $z$-score\n",
    "\n",
    "We define $z$-score\n",
    "$$z(X=x) := \\frac{x - \\mu}{\\sigma(X)},$$\n",
    "with\n",
    "$$\\sigma^2(X) := \\int_{x=-\\infty}^{x=\\infty} (x - \\mu)^2 \\Pr[X=x] dx,$$\n",
    "where $X$ is a random variable and we abuse notation a bit to let $\\Pr[X=x]$\n",
    "represent its probability density function.\n",
    "(We're going to continue to be a bit hand-wavey with this,\n",
    "assuming some mild conditions e.g. PDF is continuous.)\n",
    "\n",
    "\n",
    "### percentile\n",
    "\n",
    "We define percentile (AKA cumulative distribution function) the usual way, as\n",
    "$$Pr[X \\leq x] := \\int_{t=-\\infty}^{t=x} \\Pr[X=t] dt.$$\n",
    "\n",
    "\n",
    "### \"percentile kurtosis\"\n",
    "\n",
    "Finally, as I alluded above, I'm going to define the \"percentile kurtosis\"\n",
    "(a made-up term) $k$ of a random variable as\n",
    "$$k(X) := 1 - \\Pr[X \\leq \\mu + 4\\sigma],$$\n",
    "the complement-percentile of a $+4\\sigma$ event.\n",
    "Maximizing $k$ is equivalent to minimizing the percentile.\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "Using the definitions above, let's answer a couple quick questions.\n",
    "\n",
    "\n",
    "### Can $k$ be literally 0, i.e. $\\Pr[X \\leq \\mu + 4\\sigma] = 1$?\n",
    "\n",
    "Yes. Consider the Standard Uniform from 0 to 1.\n",
    "$$\\mu + 4\\sigma = 0.5 + 4\\sqrt{1/12} \\approx 1.65 > 1,$$\n",
    "so that a $4\\sigma$ event is not just \"essentially\" impossible,\n",
    "but \"literally\" impossible: It's literally outside the support\n",
    "of the distribution.\n",
    "\n",
    "This is not a very helpful example for our question, because\n",
    "we want to _maximize_ $k$. But it's just background.\n",
    "\n",
    "\n",
    "### Can $k$ be essentially but not literally 0?\n",
    "\n",
    "Yes, we already mentioned the example of the Standard Normal.\n",
    "\n",
    "\n",
    "### Can $k$ be some small but nontrivial positive value?\n",
    "\n",
    "Yes, the Standard $\\chi^2$ distribution has $\\mu = 1$ and $\\sigma = \\sqrt{2}$.\n",
    "In this case, $k = 1 - \\Pr[X \\leq \\mu + 4\\sigma]$ turns out to be about $0.01$.\n",
    "\n",
    "\n",
    "### Can $k$ be literally 1, i.e. $\\Pr[X \\leq \\mu + 4\\sigma] = 0$?\n",
    "\n",
    "No. This sounds silly but it's still worth convincing ourselves that\n",
    "it's truly impossible.\n",
    "\n",
    "\n",
    "Assume for simplicity that $\\mu = 0$ (this is WLOG, because if $\\mu \\neq 0$,\n",
    "we can just shift the entire distribution by $-\\mu$).\n",
    "\n",
    "\n",
    "Suppose to the contrary that it is possible, i.e. there is some\n",
    "random variable $X$ s.t. $\\Pr[X \\leq +4\\sigma] = 0$.\n",
    "Then,\n",
    "$$\\Pr[X = x] = 0 \\qquad\\;\\forall\\; x \\in (-\\infty,\\, +4\\sigma].$$\n",
    "Hence, we can collapse the expression for variance to\n",
    "$$\\sigma^2(X) = \\int_{x=+4\\sigma}^{x=+\\infty} x^2 \\Pr[X=x] dx.$$\n",
    "So we can think of the variance as a weighted average of\n",
    "squared values between $+4\\sigma$ and $+\\infty$.\n",
    "\n",
    "\n",
    "Standard deviation is of course nonnegative, so also\n",
    "$+4\\sigma \\geq 0$. So the smallest squared value\n",
    "in the weighted average is $(+4\\sigma)^2 = 16\\sigma^2$.\n",
    "Necessarily, then, the final weighted average must be\n",
    "at least $16\\sigma^2$. (Actually, it must be just a smidge more than $16\\sigma^2$,\n",
    "because we put zero density at exactly $X = +4\\sigma$,\n",
    "hence the smallest-possible squared value is $(+4\\sigma + \\varepsilon)^2$,\n",
    "and if we accounted for this smidge, we'd run into a contradiction\n",
    "immediately. However, I find it more illuminating at this step to draw\n",
    "the weaker conclusion, which is still true,\n",
    "but lets us run further before hitting a contradiction.)\n",
    "\n",
    "\n",
    "Hence we get\n",
    "$$\\sigma^2 \\geq 16\\sigma^2 \\implies \\sigma = 0.$$\n",
    "\n",
    "\n",
    "So supposing that $k$ can be $1$ for some distribution,\n",
    "that distribution must have zero variance.\n",
    "\n",
    "\n",
    "Well, according to a convention, the Dirac delta is the\n",
    "unique probability density function with zero variance\n",
    "(take this for granted, or if you insist on arguing, email me).\n",
    "It characterizes the density of a point mass.\n",
    "\n",
    "\n",
    "So let's try it out. Supposing $X$ is a Dirac-delta-distributed\n",
    "random variable (AKA a constant), we have\n",
    "$$\\Pr[X \\leq +4\\sigma] = \\Pr[X \\leq 0] = 1.$$\n",
    "\n",
    "\n",
    "Sadly, this failed. We had assumed the exact opposite:\n",
    "that $\\Pr[X \\leq 0] = 0$.\n",
    "Hence by contradition, we have Q.E.D.\n",
    "\n",
    "\n",
    "### What about the evil Cauchy (AKA Standard $t$) distribution?\n",
    "\n",
    "Obviously, one of the immediate problems with the Cauchy\n",
    "(that indeed disqualifies it from consideration)\n",
    "is that its variance (or even its mean) is not finite.\n",
    "\n",
    "\n",
    "But it can be instructive to think about it.\n",
    "If we \"define\" $\\sigma(X) := \\infty$ (acceptable)\n",
    "and $\\mu(X) := 0$ (please don't haunt my dreams Prof Blitzstein)\n",
    "for a Cauchy random variable,\n",
    "then $\\mu(X) + 4\\sigma(X) = +\\infty$, which is the upper bound of support\n",
    "for the Cauchy, hence $k(X) = 0$, just like for the Standard Uniform.\n",
    "\n",
    "\n",
    "The problem here is that the fat tails of the Cauchy\n",
    "are _so_ fat, that they make its standard deviation infinite.\n",
    "At that point, it becomes impossible to push any probability mass\n",
    "at all beyond $\\mu+4\\sigma$, because there's no more number line\n",
    "remaining after that.\n",
    "\n",
    "\n",
    "## The quick-and-dirty exploration\n",
    "\n",
    "Obviously, the best would be to solve for the maximal $k$ analytically in closed form. Letting WLOG $\\mu = 0$, we want to solve\n",
    "$$\\max_{f \\in F} \\int_{x=\\ell}^{x=+\\infty} f(x)dx,$$\n",
    "where $F$ is the set of well-formed PDF's and\n",
    "$$\\ell := 4\\sqrt{\\int_{t=-\\infty}^{t=+\\infty} t^2 f(t)dt}.$$\n",
    "This doesn't look impossible but it certainly looks very boring and I haven't got any good ideas about how to begin.\n",
    "\n",
    "\n",
    "The worst would be Monte Carlo, which I've genuinely gotten as a suggestion here. Monte Carlo is good for pinning down \"averages\" but necessarily always as good for pinning down \"extremes\".\n",
    "\n",
    "\n",
    "I will compromise by selecting some high \"resolution\" $N$ and simply systematically generating and analyzing all the possible discrete PMF's available at this resolution. This program is in essence combinatorial (factorial) so $N$ will be limited by how long I'm willing to let my notebook run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Tuple, Generator\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PMF: type = pd.Series  # int index, float data\n",
    "\n",
    "N: int = 5\n",
    "\n",
    "\n",
    "def gen_perms(len_: int=N, sum_: int=N) -> Generator[Tuple[int], None, None]:\n",
    "    \"\"\"\n",
    "    Generate permutations of Naturals $\\{0, 1, 2, ...\\}$ with length `len_` and sum `sum_`.\n",
    "    Each permutation is a tuple of the form `(n_0, n_1, n_2, ..., n_{len_-1})`.\n",
    "    \n",
    "    This is pretty general code, but we're going to keep it simple by fixing some large `N`,\n",
    "    and then analyzing `gen_perms(len_=N, sum_=N)`. In this usage, `N` represents our\n",
    "    \"resolution\": Ultimately, we'll normalize (elementwise) each permutation by `N` itself and\n",
    "    thereby yield a well-formed PMF. It's convenient to let `sum_ := len_` because\n",
    "    then we can perfectly encode a Uniform PMF as an $N$-tuple of 1's.\n",
    "    \n",
    "    You might notice that as `N` increases, so does the support of our PMF:\n",
    "    That's OK. The key is that larger `N` gives us more flexibility to create\n",
    "    finer and finer \"shapes\" for the PMF. It doesn't matter that in the process\n",
    "    of creating these shapes, we stretch out the support, because you can always\n",
    "    just imagine analyzing instead the PMF of the random variable $X/N$ i.e. our\n",
    "    random variable $X$ divided by our fixed resolution $N$, thereby shrinking the support\n",
    "    back down to the interval $[0, 1]$. Results will be equivalent for our purposes.\n",
    "    \n",
    "    Dynamic programming generator:\n",
    "    The former saves time and the latter saves space.\n",
    "    Recursive solution, inspired by https://stackoverflow.com/a/7748851.\n",
    "    \"\"\"\n",
    "    if len_ < 1:\n",
    "        raise ValueError(len_)\n",
    "    if sum_ < 0:\n",
    "        raise ValueError(sum_)\n",
    "    \n",
    "    # base case\n",
    "    if len_ == 1:\n",
    "        # only choice is singleton tuple with `sum_` as its only element\n",
    "        yield (sum_,)\n",
    "    # recursive case\n",
    "    else:\n",
    "        # iterate over choices for head (first) element i.e. $n_0$\n",
    "        for head in range(sum_ + 1):\n",
    "            \"\"\"\n",
    "            Now having fixed the head, recursively generate choices for\n",
    "            the tail (remaining) elements i.e. $n_1, ..., n_{len_-1}$.\n",
    "            Tail must be `len_ - 1` elements long, and sum to `sum_ - head`.\n",
    "            \"\"\"\n",
    "            for tail in gen_perms(len_=len_-1, sum_=sum_-head):\n",
    "                # concatenate tuples\n",
    "                yield (head,) + tail\n",
    "\n",
    "\n",
    "def get_pmf_from_perm(perm: Tuple[int]) -> PMF:\n",
    "    \"\"\"\n",
    "    Normalize a tuple of ints by its sum, creating a PMF.\n",
    "    \n",
    "    input\n",
    "    -----\n",
    "    perm: Tuple[int], a permutation of Naturals\n",
    "        e.g. `(3, 1, 0, 1)`.\n",
    "    \n",
    "    output\n",
    "    -----\n",
    "    PMF, a well-formed PMF\n",
    "        e.g. `pd.Series({0: 0.6, 1: 0.2, 2: 0.0, 3: 0.2})`.\n",
    "    \"\"\"\n",
    "    return pd.Series(perm) / sum(perm)\n",
    "\n",
    "\n",
    "def calc_mean(pmf: PMF) -> float:\n",
    "    # pmf-weighted average\n",
    "    return sum(pmf.index * pmf)\n",
    "\n",
    "\n",
    "def calc_std(pmf: PMF) -> float:\n",
    "    squared_centered_values = (pmf.index - calc_mean(pmf=pmf))**2\n",
    "    # again, just a pmf-weighted average\n",
    "    return sum(squared_centered_values * pmf)\n",
    "\n",
    "\n",
    "def calc_pctl(pmf: PMF, x: float=0) -> float:\n",
    "    return pmf.loc[:x].sum()\n",
    "\n",
    "\n",
    "def calc_pctl_kurt(pmf: PMF) -> float:\n",
    "    mu = calc_mean(pmf=pmf)\n",
    "    sigma = calc_std(pmf=pmf)\n",
    "    pctl = calc_pctl(pmf=pmf, x=mu + 4*sigma)\n",
    "    return 1 - pctl\n",
    "\n",
    "\n",
    "def plot_pmf(pmf: PMF) -> None:\n",
    "    pmf.plot(kind=\"area\", title=f\"PMF (pctl-kurt: {calc_pctl_kurt(pmf=pmf):.2f})\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main() -> Tuple[float, PMF]:\n",
    "    max_pctl_kurt = 0  # the maximal pctl-kurt seen so far\n",
    "    argmax_pctl_kurt = None  # the PMF that gave rise to it\n",
    "\n",
    "    for perm in gen_perms():\n",
    "        pmf = get_pmf_from_perm(perm=perm)\n",
    "        pctl_kurt = calc_pctl_kurt(pmf=pmf)\n",
    "        assert not pd.isnull(pctl_kurt), \\\n",
    "            (pmf, pctl_kurt)\n",
    "        if pctl_kurt > max_pctl_kurt:\n",
    "            max_pctl_kurt = pctl_kurt\n",
    "            argmax_pctl_kurt = pmf\n",
    "\n",
    "    plot_pmf(pmf=argmax_pctl_kurt)\n",
    "    return max_pctl_kurt, argmax_pctl_kurt\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    max_pctl_kurt, argmax_pctl_kurt = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
