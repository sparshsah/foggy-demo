{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Joint vs Individual Linear Regression Loadings\n",
    "\n",
    "First, some notation. Be warned that I am going to take advantage of the typographical similarity between certain Greek and Roman letters (classicists and pedants, avert thy eyes!). Other than that, however, my notation should be very natural to anyone who's taken a college-level linear models course.\n",
    "\n",
    "Afterward, I'll run some experiments where I prove (or at least state) some theoretical (ground-truth) results about the \"Greek\" quantities, then demonstrate them using their \"Roman\" counterparts calculated on toy datasets. To give a trivial example, to demonstrate that $\\sigma(\\gamma) \\geq 0$, I could show that $s(y) = 0.42$ (which is nonnegative) for some specific toy dataset.\n",
    "\n",
    "\n",
    "## The Greeks: Ground-Truth Data-Generating Process\n",
    "\n",
    "Let $\\gamma,\\, \\chi_1,\\, \\chi_2,\\, \\varepsilon \\mid \\beta_0,\\, \\beta_1,\\, \\beta_2$ be a finite-variance (and nonzero-variance) Multivariate Normal \"data-generating process\" (basically, a vector of real-valued random variables) such that $\\gamma = \\beta_0 + \\beta_1\\chi_1 + \\beta_2\\chi_2 + \\varepsilon$ where $\\varepsilon$ is i.i.d. white noise.\n",
    "\n",
    "Let $\\sigma(\\cdot)$ represent standard deviation, $\\sigma^2(\\cdot)$ represent variance, $\\sigma^2(\\cdot,\\, \\cdot)$ represent covariance, and $\\rho(\\cdot,\\, \\cdot)$ represent correlation. Let $\\Sigma$ be the variance-covariance matrix between $\\chi_1$ and $\\chi_2$ i.e.\n",
    "$$\\begin{pmatrix} \\sigma^2(\\chi_1) & \\sigma^2(\\chi_1,\\, \\chi_2) \\\\ \\sigma^2(\\chi_1,\\, \\chi_2) & \\sigma^2(\\chi_2)\\end{pmatrix},$$\n",
    "$\\Omega$ be the corresponding correlation matrix, and $\\Sigma_\\gamma$ be the column vector $[\\sigma^2(\\chi_1,\\, \\gamma) ,\\, \\sigma^2(\\chi_2,\\, \\gamma)]$ of covariances between the $\\chi$'s and $\\gamma$.\n",
    "\n",
    "Importantly, assume that $|\\rho(\\chi_1,\\, \\chi_2)| \\neq 1$.\n",
    "\n",
    "\n",
    "## The Romans: Practical Calculations On Observed Data\n",
    "\n",
    "Suppose we observe $N$ different \"draws\" or \"samples\" from this process. Arrange the draws of $\\gamma$ into a column vector of real numbers $y := [y_n]$, the draws of $\\chi_1$ into a column vector of real numbers $x_1 := [x_{n,1}]$, the draws of $\\chi_2$ into a column vector of real numbers $x_2 := [x_{n,2}]$, and the draws of $\\varepsilon$ into a column vector of real numbers $e := [e_n]$, over $n \\in [1,\\, N]$. Further, arrange the $x$'s into an $N \\times 3$ matrix of real numbers $X := [1,\\, x_1,\\, x_2]$ whose first column is all ones (AKA \"constant\" AKA \"intercept\").\n",
    "\n",
    "Let the vector of real numbers $b := [b_0,\\, b_1,\\, b_2] := (X^\\top X)^{-1} X^\\top y$ be the coefficients from an OLS linear regression of $y$ onto $X$ [1]. More generally, define $\\texttt{ols}$ such that e.g. $\\texttt{ols}(y,\\, [1,\\, x_1,\\, x_2]) := [b_0, b_1, b_2] =: b$.\n",
    "\n",
    "Finally, let $s$, $s^2$, $r$, $S$, $U$, and $S_y$ be the usual Bessel-corrected \"sample\" estimators of their \"population\" counterparts in Greek above.\n",
    "\n",
    "\n",
    "Footnotes\n",
    "---------\n",
    "[1] Take this formula for granted. Recall that if $\\varepsilon$ is Normally distributed, then OLS yields the MLE for $\\beta$ given $y,\\, X$. On the other hand if $\\varepsilon$ is Laplace-distributed, then instead LAD would yield the MLE."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        library        us\n",
       "const -0.000431 -0.000431\n",
       "x1     1.000214  1.000214\n",
       "x2     1.000238  1.000238"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>library</th>\n      <th>us</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>-0.000431</td>\n      <td>-0.000431</td>\n    </tr>\n    <tr>\n      <th>x1</th>\n      <td>1.000214</td>\n      <td>1.000214</td>\n    </tr>\n    <tr>\n      <th>x2</th>\n      <td>1.000238</td>\n      <td>1.000238</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from typing import Tuple, Union, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "def gen_data(mean: Tuple[float]=(0, 0, 0), std: Tuple[float]=(1, 1, 1),\n",
    "             corr12: float=0, corr13: float=0, corr23: float=0,\n",
    "             b: Tuple[float]=(0, 1, 1, 1, 1), x3: bool=False,\n",
    "             n: int=10_000_000, seed: int=42) -> \\\n",
    "            Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Generate a toy dataset where y = b0 + b1*x1 + b2*x2 [+ b3*x3] + b4*white_noise.\n",
    "\n",
    "    input\n",
    "    -----\n",
    "    mean: tuple[float] (default 0), ground-truth means of the x's.\n",
    "    std: tuple[float] (default 1), ground-truth standard deviations of the x's.\n",
    "    corr`ij`: float (default 0), ground-truth correlation between the x's.\n",
    "    b: tuple[float], ground-truth beta's.\n",
    "    x3: bool, whether to use x3.\n",
    "    n: int (default 10 million), number of data points to generate.\n",
    "    seed: int (default 42), random seed.\n",
    "\n",
    "    output\n",
    "    ------\n",
    "    _X: pd.DataFrame, X: pd.DataFrame, white_noise: pd.Series, y: pd.Series.\n",
    "    \"\"\"\n",
    "    mean = pd.Series({\"x1\": mean[0], \"x2\": mean[1], \"x3\": mean[2], \"white_noise\": 0})\n",
    "    std = pd.Series({\"x1\": std[0], \"x2\": std[1], \"x3\": std[2], \"white_noise\": 1})\n",
    "    # diagonal matrix with std's on the diagonal\n",
    "    std_ = pd.DataFrame(np.diag(std), index=std.index, columns=std.index)\n",
    "    corr = pd.DataFrame({\n",
    "        \"x1\": {\"x1\": 1, \"x2\": corr12, \"x3\": corr13, \"white_noise\": 0},\n",
    "        \"x2\": {\"x1\": corr12, \"x2\": 1, \"x3\": corr23, \"white_noise\": 0},\n",
    "        \"x3\": {\"x1\": corr13, \"x2\": corr23, \"x3\": 1, \"white_noise\": 0},\n",
    "        \"white_noise\": {\"x1\": 0, \"x2\": 0, \"x3\": 0, \"white_noise\": 1}\n",
    "    })\n",
    "    cov = std_ @ corr @ std_\n",
    "    \n",
    "    df = pd.DataFrame(np.random.default_rng(seed=seed).multivariate_normal(mean=mean, cov=cov, size=n),\n",
    "                      columns=mean.index)\n",
    "    _X = df[[\"x1\", \"x2\", \"x3\"]] if x3 else df[[\"x1\", \"x2\"]]\n",
    "    y = b[0] + b[1]*df[\"x1\"] + b[2]*df[\"x2\"] + b[4]*df[\"white_noise\"] + (b[3]*df[\"x3\"] if x3 else 0)\n",
    "    return _X, sm.add_constant(_X), df[\"white_noise\"], pd.Series(y, name=\"y\")\n",
    "\n",
    "\n",
    "def cov(X: Union[pd.DataFrame, pd.Series], y: Optional[pd.Series]=None) -> Union[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Return covariance matrix of `X` if `y` is None, else covariance between `X` and `y`.\"\"\"\n",
    "    return X.cov() if y is None else pd.concat([X, y], axis=\"columns\").cov()[\"y\"].drop(labels=\"y\")\n",
    "\n",
    "\n",
    "def ols(X: pd.DataFrame, y: pd.Series, hasconst=True, use_lib=True) -> pd.Series:\n",
    "    \"\"\"Get OLS coefficient vector.\"\"\"\n",
    "    if not hasconst:\n",
    "        raise ValueError(hasconst)\n",
    "    return sm.OLS(exog=X, endog=y, hasconst=hasconst).fit().params if use_lib else \\\n",
    "        pd.Series(inv(X.T @ X) @ (X.T @ y), index=X.columns)\n",
    "\n",
    "\n",
    "# example\n",
    "_, X, _, y = gen_data()\n",
    "pd.DataFrame({\"library\": ols(X=X, y=y), \"us\": ols(X=X, y=y, use_lib=False)}, columns=[\"library\", \"us\"])"
   ]
  },
  {
   "source": [
    "## Result 0.0: Bivariate Loading = Univariate Loading\n",
    "\n",
    "Suppose $\\rho(\\chi_1,\\, \\chi_2) = 0$. Then, $\\beta_i = \\sigma^{-2}(\\chi_i)\\sigma^2(\\chi_i,\\, \\gamma)$. This is the familiar formula for a univariate regression slope, otherwise stated as $\\beta_i = \\frac{\\texttt{Cov}(\\chi_i,\\, \\gamma)}{\\texttt{Var}(\\chi_i)}$. Notice how similar this looks to the $(X^\\top X)^{-1} X^\\top y$ formula.\n",
    "\n",
    "Stating the above another way: If the regressors are uncorrelated, then the slope on either regressor in a bivariate regression will be the same as the slope on that regressor in a univariate regression, and it is valid to reduce the bivariate problem to two separate univariate problems.\n",
    "\n",
    "Pf: Trivial. For example, consider the data-generating process $\\gamma,\\, \\chi_1,\\, \\varepsilon^\\prime$ where $\\gamma = \\beta_0 + \\beta_2\\texttt{E}(\\chi_2) + \\beta_1\\chi_1 + \\varepsilon + \\beta_2(\\chi_2 - \\texttt{E}(\\chi_2))$ which we write as $\\beta_0^\\prime + \\beta_1\\chi_1 + \\varepsilon^\\prime$ with $\\sigma^2(\\varepsilon^\\prime) = \\sigma^2(\\varepsilon) + \\beta_2^2\\sigma^2(\\chi_2)$. This latter form is amenable to univarate OLS, which by construction must be consistent with our original multivariate formulation.\n",
    "\n",
    "### Corollary 0.0.C\n",
    "Let $[a_0,\\, a_1] := \\texttt{ols}(y,\\, [1, x_1])$, $[b_0,\\, b_2] := \\texttt{ols}(y,\\, [1, x_2])$, $[c_0,\\, c_1,\\, c_2] := \\texttt{ols}(y,\\, [1, x_1,\\, x_2])$. We will have $c_0 = a_0 + b_0 - \\bar{y}$, $c_1 = a_1$, and $c_2 = b_2$ iff $r(x_1,\\, x_2) = 0$.\n",
    "\n",
    "Pf: I cheat a bit and use Result 0.1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       bvl  uvl1  uvl2\n",
       "const  1.6   9.0  14.6\n",
       "x1     3.1   3.1   NaN\n",
       "x2     2.7   NaN   2.7"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bvl</th>\n      <th>uvl1</th>\n      <th>uvl2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>1.6</td>\n      <td>9.0</td>\n      <td>14.6</td>\n    </tr>\n    <tr>\n      <th>x1</th>\n      <td>3.1</td>\n      <td>3.1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x2</th>\n      <td>2.7</td>\n      <td>NaN</td>\n      <td>2.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "_, X, _, y = gen_data(mean=(4.13, 2.72, 0), b=(1.62, 3.14, 2.72, 1, 1))\n",
    "df = pd.DataFrame({\"bvl\": ols(X=X, y=y),\n",
    "                   \"uvl1\": ols(X=X[[\"const\", \"x1\"]], y=y),\n",
    "                   \"uvl2\": ols(X=X[[\"const\", \"x2\"]], y=y)})\n",
    "np.round(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.6, 1.6)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# c0 = a0 + b0 - ybar\n",
    "round(df.loc[\"const\", \"bvl\"], 1), \\\n",
    "round(df.loc[\"const\", \"uvl1\":\"uvl2\"].sum() - y.mean(), 1)"
   ]
  },
  {
   "source": [
    "## Result 0.0.1: Univariate-Loading Formula Generalizes Naturally to Higher Dimensions\n",
    "\n",
    "$[\\beta_1,\\, \\beta_2] = \\Sigma^{-1}\\Sigma_\\gamma$. Thence, $\\beta_0$ can be determined by $\\beta_0 = \\texttt{E}(\\gamma) - (\\beta_1\\texttt{E}(\\chi_1) + \\beta_2\\texttt{E}(\\chi_2))$.\n",
    "\n",
    "Pf: Exercise of doing the OLS matrix calculations \"pictorally\" (using hand-drawn matrices and symbolic algebra software) for the bivariate case where $\\texttt{E}(\\chi_1) = 0 = \\texttt{E}(\\chi_2)$ with $N$ observations left to the reader. (Tip: You have to go pretty far along in the calculations, the intermediate steps will have pieces that you recognize, but they're going to be attached to extraneous stuff that will eventually square away. It's annoying and I half-question whether I _truly_ got the right answer, or my confirmation bias just tricked me accidentally stumbling onto the right final form.) Thence, prove the theoretical result by representing the underlying Bivariate Normal distribution as an $\\infty \\times 2$ matrix. Fair disclosure: I have myself done the first step but haven't done the second step which requires a level of linear algebra that I just barely got to in college. However, from my vague recollection of that semester, I can't imagine how it could fail to work. (Famous last words..)\n",
    "\n",
    "I also haven't done it for the case where $\\texttt{E}(\\chi_i) \\neq 0$, but I've seen enough empirical evidence that I'm willing to accept on faith that it works.\n",
    "\n",
    "And I certainly haven't done it for the general multivariate (trivariate = $x_1,\\, x_2,\\, x_3$, tetravariate = $x_1,\\, x_2,\\, x_3,\\, x_4$, etc) case, but I'm going to use the [arcane pattern](https://sparshsah.github.io/tablinum/lessons.html) that in statistics, things either work nowhere (i.e. in only zero dimensions), in only one dimension, only one or two dimensions, only three-or-more dimensions, or everywhere. I've shown that it works in both one, two, _and_ three dimensions, hence it must work everywhere.\n",
    "\n",
    "I'm sure there's a much more sophisticated way of proving this by visualizing the problem as a vector-space projection or something, but somebody will have to show it to me."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        library        us\n",
       "const  0.000363       NaN\n",
       "x1     0.999411  0.999411\n",
       "x2     0.999886  0.999886"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>library</th>\n      <th>us</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>0.000363</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x1</th>\n      <td>0.999411</td>\n      <td>0.999411</td>\n    </tr>\n    <tr>\n      <th>x2</th>\n      <td>0.999886</td>\n      <td>0.999886</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# N must be large enough that np.allclose(_X.mean(), 0)\n",
    "_X, X, _, y = gen_data(corr12=0.5)\n",
    "pd.DataFrame({\"library\": ols(X=X, y=y), \"us\": pd.Series(inv(cov(_X)) @ cov(_X, y), index=_X.columns)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        library        us\n",
       "const  0.002521       NaN\n",
       "x1     0.999411  0.999411\n",
       "x2     0.999886  0.999886"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>library</th>\n      <th>us</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>0.002521</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x1</th>\n      <td>0.999411</td>\n      <td>0.999411</td>\n    </tr>\n    <tr>\n      <th>x2</th>\n      <td>0.999886</td>\n      <td>0.999886</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# works even if E(\\chi_i) != 0\n",
    "_X, X, _, y = gen_data(mean=(3.14, 2.72, 0), corr12=0.5)\n",
    "pd.DataFrame({\"library\": ols(X=X, y=y), \"us\": pd.Series(inv(cov(_X)) @ cov(_X, y), index=_X.columns)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        library        us\n",
       "const  1.620363       NaN\n",
       "x1     0.999411  0.999411\n",
       "x2     0.999886  0.999886"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>library</th>\n      <th>us</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>1.620363</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x1</th>\n      <td>0.999411</td>\n      <td>0.999411</td>\n    </tr>\n    <tr>\n      <th>x2</th>\n      <td>0.999886</td>\n      <td>0.999886</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# works even if \\beta_0 != 0\n",
    "_X, X, _, y = gen_data(corr12=0.5, b=(1.62, 1, 1, 1, 1))\n",
    "pd.DataFrame({\"library\": ols(X=X, y=y), \"us\": pd.Series(inv(cov(_X)) @ cov(_X, y), index=_X.columns)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        library        us\n",
       "const  1.620025       NaN\n",
       "x1     1.337008  1.337008\n",
       "x2     7.330978  7.330978"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>library</th>\n      <th>us</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>1.620025</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x1</th>\n      <td>1.337008</td>\n      <td>1.337008</td>\n    </tr>\n    <tr>\n      <th>x2</th>\n      <td>7.330978</td>\n      <td>7.330978</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "_X, X, _, y = gen_data(mean=(3.14, 2.72, 0), std=(42, 24, 1), corr12=.42, b=(1.62, 1.337, 7.331, 1, 1))\n",
    "pd.DataFrame({\"library\": ols(X=X, y=y), \"us\": pd.Series(inv(cov(_X)) @ cov(_X, y), index=_X.columns)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         library         us\n",
       "const   1.619596        NaN\n",
       "x1      1.336999   1.336999\n",
       "x2      7.330988   7.330988\n",
       "x3     31.400003  31.400003"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>library</th>\n      <th>us</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>1.619596</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x1</th>\n      <td>1.336999</td>\n      <td>1.336999</td>\n    </tr>\n    <tr>\n      <th>x2</th>\n      <td>7.330988</td>\n      <td>7.330988</td>\n    </tr>\n    <tr>\n      <th>x3</th>\n      <td>31.400003</td>\n      <td>31.400003</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# craziest combination i could think of\n",
    "_X, X, _, y = gen_data(mean=(3.14, 2.72, 4.13), std=(42, 24, 4.2),\n",
    "                       corr12=.42, corr13=-.42, corr23=0.24,\n",
    "                       b=(1.62, 1.337, 7.331, 31.4, 1), x3=True)\n",
    "pd.DataFrame({\"library\": ols(X=X, y=y), \"us\": pd.Series(inv(cov(_X)) @ cov(_X, y), index=_X.columns)})"
   ]
  },
  {
   "source": [
    "## Result 0.1: BVL != UVL\n",
    "\n",
    "Suppose $\\rho(\\chi_1,\\, \\chi_2) \\neq 0$. Then, the conclusion of Result 0.0 will not hold. Notice this essentially turns Result 0.0 into an \"if and only if\" statement. (Ignore the uninteresting case where e.g. $\\beta_2 = 0$.)\n",
    "\n",
    "Pf: By contradition. Suppose to the contrary that e.g. $\\beta_1 = \\sigma^{-2}(\\chi_1)\\sigma^2(\\chi_1,\\, \\gamma)$. Take for granted the results that $a_1 := s^{-2}(x_1)s^2(x_1,\\, y)$ is an *un*biased estimator of $\\sigma^{-2}(\\chi_1)\\sigma^2(\\chi_1,\\, \\gamma)$ (which we have supposed is the same as $\\beta_1$), and that $a_1$ interpreted as a univariate OLS slope estimate for $\\beta_1$ has omitted-variable bias of $\\beta_2 \\sigma^{-2}(\\chi_1) \\sigma^2(\\chi_1,\\, \\chi_2)$. We assume finite and nonzero variance, and in this scenario are supposing that $\\rho(\\chi_1,\\, \\chi_2) \\neq 0 \\implies \\sigma^2(\\chi_1,\\, \\chi_2) \\neq 0$. Therefore, the OVB is nonzero and $a_1$ is a biased estimator of $\\beta_1$. We therefore conclude that $a_1$ is simultaneously both a unbiased and a biased estimator of the same value. Hence by contradiction, QED."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       library  uvl1  uvl2\n",
       "const      0.0  -0.0   0.0\n",
       "x1         1.0   1.5   NaN\n",
       "x2         1.0   NaN   1.5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>library</th>\n      <th>uvl1</th>\n      <th>uvl2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>0.0</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>x1</th>\n      <td>1.0</td>\n      <td>1.5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x2</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# even in this simple case, it fails (although thanks to our setup, it is nice and symmetric)\n",
    "# notice that as expected, the OVB on the UVL's is positive\n",
    "_, X, _, y = gen_data(corr12=0.5)\n",
    "df = pd.DataFrame({\"library\": ols(X=X, y=y),\n",
    "                   \"uvl1\": ols(X=X[[\"const\", \"x1\"]], y=y),\n",
    "                   \"uvl2\": ols(X=X[[\"const\", \"x2\"]], y=y)})\n",
    "np.round(df, 2)"
   ]
  },
  {
   "source": [
    "## Result 1: Results About the \"SumVL\"\n",
    "\n",
    "In the following section, we explore interesting properties of some misspecified regression models. Let $[a_0,\\, a_1] := \\texttt{ols}(y,\\, [1, x_1])$, $[b_0,\\, b_2] := \\texttt{ols}(y,\\, [1, x_2])$, $[c_0,\\, c_{1+2}] := \\texttt{ols}(y,\\, [1, x_1+x_2])$.\n",
    "\n",
    "Caution: When a regression model is misspecified, it will not in general yield coefficient estimates that are good estimates for the ground-truth $\\beta$! But the calculation itself just linear algebra, it can of course be done even if it lacks good motivation or interpretation.\n",
    "\n",
    "Recall also that although in the below examples you know what the ground-truth $\\beta$ is because it's an input to our data sampler, even if you didn't, you could get it by calculating the ground-truth expectation $\\texttt{E}((X^\\top X)^{-1}  X^\\top y)$, since the random variable inside the expectation operator is an unbiased estimator for $\\beta$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Result 1.0: SumVL = UVL\n",
    "\n",
    "That is, $c_0 = a_0 = b_0$ and $c_{1+2} = a_1 = b_2$. Obviously, if the individual UVL's differ from each other, this stricter relationship cannot be true. However, supposing the UVL's _do_ match, then this will be true iff $\\bar{x_1} = 0 = \\bar{x_2}$ and $r(x_1,\\, x_2) = 0$. (I'm ignoring the case where $a_1 = 0 \\iff r(x_1,\\, y) = 0$, which is uninteresting: Trivially, we can make both $x_i$'s totally unrelated to $y$ and then we will have slopes of zero and intercepts of $\\bar{y}$.)\n",
    "\n",
    "Pf: As will become a recurring theme in this section, we'll work our way backward. First of all (or perhaps.. last of all.. heh), we're assuming the slopes match i.e.\n",
    "$$s^{-2}(x_1) s^2(x_1,\\, y) =: a_1 = b_2 := s^{-2}(x_2) s^2(x_2,\\, y).$$\n",
    "Let's collapse this and define $k := s^2(x_2) / s^2(x_1)$ so that we can write\n",
    "$$s^{-2}(x_1) s^2(x_1,\\, y) = k^{-1}s^{-2}(x_1) s^2(x_2,\\, y)$$\n",
    "$$s^2(x_1,\\, y) = k^{-1} s^2(x_2,\\, y)$$\n",
    "$$k s^2(x_1,\\, y) = s^2(x_2,\\, y).$$\n",
    "\n",
    "Now we can also write\n",
    "$$c_{1+2} = \\frac{s^2(x_1 + x_2,\\, y)}{s^2(x_1 + x_2)} = \\frac{s^2(x_1,\\, y) + s^2(x_2,\\, y)}{s^2(x_1) + s^2(x_2) + 2r(x_1,\\, x_2)s(x_1)s(x_2)}$$\n",
    "Then substitute\n",
    "$$= \\frac{s^2(x_1,\\, y) + ks^2(x_1,\\, y)}{s^2(x_1) + ks^2(x_1) + 2r(x_1,\\, x_2)s(x_1)s(x_2)}$$\n",
    "Now the numerator is $(1+k)s^2(x_1,\\, y)$ so the only way for the entire thing to match $a_1$ is for the denominator to be $(1+k)s^2(x_1)$ and the only way for that to be possible is for $\\boxed{  r(x_1,\\, x_2) = 0  }$ (let's ignore the degenerate case where e.g. $s(x_1) = 0$).\n",
    "\n",
    "On to the intercepts. Let's write\n",
    "$$\\bar{y} - a_1\\bar{x_1} =: a_0 = b_0 := \\bar{y} - b_2\\bar{x_2} = \\bar{y} - a_1\\bar{x_2} \\implies \\boxed{  \\bar{x_1} = \\bar{x_2}  }.$$\n",
    "We want also\n",
    "$$a_0 = c_0 := \\bar{y} - c_{1+2}\\bar{x_1 + x_2} = \\bar{y} - a_1(\\bar{x_1} + \\bar{x_2}) = \\bar{y} - a_1\\bar{x_1} - a_1\\bar{x_2} = \\bar{y} - a_1\\bar{x_1} - a_1\\bar{x_1} = \\bar{y} - 2a_1\\bar{x_1}.$$\n",
    "Uh-oh. This means\n",
    "$$\\bar{y} - a_1\\bar{x_1} = \\bar{y} - 2a_1\\bar{x_1}..$$\n",
    "Either $a_1 = 0$ (the uninteresting case we ignore above) or $\\boxed{  \\bar{x_1} = 0  }$. QED."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       bvl  uvl1  uvl2  uvl1+2\n",
       "const -0.0  -0.0  -0.0    -0.0\n",
       "x1     1.0   1.0   NaN     NaN\n",
       "x2     1.0   NaN   1.0     NaN\n",
       "x1+x2  NaN   NaN   NaN     1.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bvl</th>\n      <th>uvl1</th>\n      <th>uvl2</th>\n      <th>uvl1+2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n    </tr>\n    <tr>\n      <th>x1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x2</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x1+x2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# simple (almost trivial) case\n",
    "_, X, _, y = gen_data()\n",
    "X1 = sm.add_constant(X[\"x1\"])\n",
    "X2 = sm.add_constant(X[\"x2\"])\n",
    "X12 = sm.add_constant(pd.Series(X[\"x1\"] + X[\"x2\"], name=\"x1+x2\"))\n",
    "\n",
    "np.round(pd.DataFrame({\"bvl\": ols(y=y, X=X),\n",
    "                       \"uvl1\": ols(y=y, X=X1),\n",
    "                       \"uvl2\": ols(y=y, X=X2),\n",
    "                       \"uvl1+2\": ols(y=y, X=X12)},\n",
    "                      index=[\"const\", \"x1\", \"x2\", \"x1+x2\"]),\n",
    "         1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       bvl  uvl1  uvl2  uvl1+2\n",
       "const  3.1   3.1   3.1     3.1\n",
       "x1     2.7   2.7   NaN     NaN\n",
       "x2     2.7   NaN   2.7     NaN\n",
       "x1+x2  NaN   NaN   NaN     2.7"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bvl</th>\n      <th>uvl1</th>\n      <th>uvl2</th>\n      <th>uvl1+2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>3.1</td>\n      <td>3.1</td>\n      <td>3.1</td>\n      <td>3.1</td>\n    </tr>\n    <tr>\n      <th>x1</th>\n      <td>2.7</td>\n      <td>2.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x2</th>\n      <td>2.7</td>\n      <td>NaN</td>\n      <td>2.7</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x1+x2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# more interesting case (variances are unequal, and intercept is nontrivial)\n",
    "_, X, _, y = gen_data(std=(1, 2, 1), b=(3.14, 2.72, 2.72, 0, 1))\n",
    "X1 = sm.add_constant(X[\"x1\"])\n",
    "X2 = sm.add_constant(X[\"x2\"])\n",
    "X12 = sm.add_constant(pd.Series(X[\"x1\"] + X[\"x2\"], name=\"x1+x2\"))\n",
    "\n",
    "np.round(pd.DataFrame({\"bvl\": ols(y=y, X=X),\n",
    "                       \"uvl1\": ols(y=y, X=X1),\n",
    "                       \"uvl2\": ols(y=y, X=X2),\n",
    "                       \"uvl1+2\": ols(y=y, X=X12)},\n",
    "                      index=[\"const\", \"x1\", \"x2\", \"x1+x2\"]),\n",
    "         1)"
   ]
  },
  {
   "source": [
    "## Result 1.1: SumVL = Average UVL\n",
    "\n",
    "This is a generalization of Result 1.0, here we want merely $c_0 = 0.5 a_0 + 0.5 b_0$ and $c_{1+2} = 0.5 a_1 + 0.5 b_2$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(sparshsah)"
   ]
  },
  {
   "source": [
    "## Result 1.2: SumVL = Sum of UVL's\n",
    "\n",
    "Under what conditions will we have $c_0 = a_0 + b_0$ and $c_{1+2} = a_1 + b_2$? Let's start backward:\n",
    "\n",
    "$$a_1 = \\frac{s^2(x_1,\\, y)}{s^2(x_1)}$$\n",
    "$$b_2 = \\frac{s^2(x_2,\\, y)}{s^2(x_2)}$$\n",
    "$$a_1 + b_2 = \\frac{s^2(x_1,\\, y)}{s^2(x_1)} + \\frac{s^2(x_2,\\, y)}{s^2(x_2)} = \\frac{s^2(x_2)s^2(x_1,\\, y) + s^2(x_1)s^2(x_2,\\, y)}{s^2(x_1)s^2(x_2)}$$\n",
    "$$c_{1+2} = \\frac{s^2(x_1 + x_2,\\, y)}{s^2(x_1 + x_2)} = \\frac{s^2(x_1,\\, y) + s^2(x_2,\\, y)}{s^2(x_1) + s^2(x_2) + 2s^2(x_1,\\, x_2)}$$\n",
    "\n",
    "Hence we want\n",
    "$$\\frac{s^2(x_2)s^2(x_1,\\, y) + s^2(x_1)s^2(x_2,\\, y)}{s^2(x_1)s^2(x_2)} = \\frac{s^2(x_1,\\, y) + s^2(x_2,\\, y)}{s^2(x_1) + s^2(x_2) + 2s^2(x_1,\\, x_2)}$$\n",
    "Clearly this is underidentified so let's assert that $s(x_1) = s = s(x_2)$, whereby we get\n",
    "$$\\frac{s^2(x_1,\\, y) + s^2(x_2,\\, y)}{s^2} = \\frac{s^2(x_1,\\, y) + s^2(x_2,\\, y)}{2s^2 + 2s^2(x_1,\\, x_2)}$$\n",
    "Now the numerators match, so we just need to make the denominators match\n",
    "$$s^2 = 2s^2 + 2s^2(x_1,\\, x_2) = 2s^2 + 2r(x_1,\\, x_2)s^2 = 2(1 + r(x_1,\\, x_2))s^2$$\n",
    "$$1 = 2(1 + r(x_1,\\, x_2))$$\n",
    "$$\\boxed{    -0.5 = r(x_1,\\, x_2)    }.$$\n",
    "So if their standard deviations are the same, we need $x_1$ and $x_2$ to be $-0.5$ correlated if we want to slopes to add up.\n",
    "\n",
    "\n",
    "Now what about the intercept? Well, we know\n",
    "$$a_0 = \\bar{y} - a_1\\bar{x_1}$$ and $$b_0 = \\bar{y} - b_2\\bar{x_2}$$\n",
    "so that\n",
    "$$a_0 + b_0 = 2\\bar{y} - a_1\\bar{x_1} - b_2\\bar{x_2},$$\n",
    "and\n",
    "$$c_0 = \\bar{y} - c_{1+2}\\bar{x_1+x_2}$$\n",
    "$$= \\bar{y} - (a_1 + b_2)\\bar{x_1} - (a_1 + b_2)\\bar{x_2}$$\n",
    "$$= \\bar{y} - a_1\\bar{x_1} - b_2\\bar{x_1} - a_1\\bar{x_2} - b_2\\bar{x_2}$$\n",
    "hence we want also\n",
    "$$2\\bar{y} - a_1\\bar{x_1} - b_2\\bar{x_2} = \\bar{y} - a_1\\bar{x_1} - b_2\\bar{x_1} - a_1\\bar{x_2} - b_2\\bar{x_2}$$\n",
    "$$\\boxed{    \\bar{y} = -(a_1\\bar{x_2} + b_2\\bar{x_1})    }.$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             bvl      uvl1       uvl2     uvl1+2\n",
       "const -22.821736 -7.942412 -14.392452 -22.332507\n",
       "x1      1.619886  0.314720        NaN        NaN\n",
       "x2      2.610589       NaN   1.801025        NaN\n",
       "x1+x2        NaN       NaN        NaN   2.115421"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bvl</th>\n      <th>uvl1</th>\n      <th>uvl2</th>\n      <th>uvl1+2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>-22.821736</td>\n      <td>-7.942412</td>\n      <td>-14.392452</td>\n      <td>-22.332507</td>\n    </tr>\n    <tr>\n      <th>x1</th>\n      <td>1.619886</td>\n      <td>0.314720</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x2</th>\n      <td>2.610589</td>\n      <td>NaN</td>\n      <td>1.801025</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>x1+x2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.115421</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "x1bar, x2bar = 3.14, 4.13\n",
    "a1, b2 = 1.62, 2.61\n",
    "intercept = -22.820025177145162  # crystal ball told me this is what is needed\n",
    "\n",
    "_, X, _, y = gen_data(mean=(x1bar, x2bar, 0), corr12=-0.5, b=(intercept, a1, b2, 1, 1))\n",
    "X1 = sm.add_constant(X[\"x1\"])\n",
    "X2 = sm.add_constant(X[\"x2\"])\n",
    "X12 = sm.add_constant(pd.Series(X[\"x1\"] + X[\"x2\"], name=\"x1+x2\"))\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"bvl\": ols(y=y, X=X),\n",
    "                   \"uvl1\": ols(y=y, X=X1),\n",
    "                   \"uvl2\": ols(y=y, X=X2),\n",
    "                   \"uvl1+2\": ols(y=y, X=X12)},\n",
    "                  index=[\"const\", \"x1\", \"x2\", \"x1+x2\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-6.95, -6.95)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# ybar = -(a1 x2bar + b2 x1bar) .. just to prove that my crystal ball was right\n",
    "round(y.mean(), 2), \\\n",
    "round(-(df.loc[\"x1\", \"uvl1\"] * X[\"x2\"].mean() + df.loc[\"x2\", \"uvl2\"] * X[\"x1\"].mean()), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.12, 2.12)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# c_{1+2} = a1 + b2\n",
    "round(df.loc[\"x1+x2\", \"uvl1+2\"], 2), \\\n",
    "round(df.loc[\"x1\", \"uvl1\"] + df.loc[\"x2\", \"uvl2\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-22.33, -22.33)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# c0 = a0 + b0\n",
    "round(df.loc[\"const\", \"uvl1+2\"], 2), \\\n",
    "round(df.loc[\"const\", \"uvl1\":\"uvl2\"].sum(), 2)"
   ]
  }
 ]
}